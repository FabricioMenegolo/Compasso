{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 59\n%glue_version 3.0\n%worker_type G.1X\n%number_of_workers 2\n\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom pyspark.sql.functions import col, substring, when, size\nfrom datetime import datetime\n\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\n\n",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.37.3 \nCurrent idle_timeout is 2800 minutes.\nidle_timeout has been set to 59 minutes.\nSetting Glue version to: 3.0\nPrevious worker type: G.1X\nSetting new worker type to: G.1X\nPrevious number of workers: 5\nSetting new number of workers to: 2\nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::214541855063:role/AWSGlueServiceRole-Lab4\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 2\nSession ID: 5aa0e6bf-d11a-4e14-8b93-a7f61ea250bd\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.37.3\n--enable-glue-datacatalog true\nWaiting for session 5aa0e6bf-d11a-4e14-8b93-a7f61ea250bd to get into ready status...\nSession 5aa0e6bf-d11a-4e14-8b93-a7f61ea250bd has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Define os caminhos dos arquivos no S3\npath1 = \"s3://data-lake-do-fabricio/Raw/Local/CSV/Movies/2023/05/02/\"\npath2 = \"s3://data-lake-do-fabricio/Raw/Local/CSV/Series/2023/05/02/\"\npath3 = \"s3://data-lake-do-fabricio/Raw/TMDB/JSON/Movies/2023/05/24/\"\npath4 = \"s3://data-lake-do-fabricio/Raw/TMDB/JSON/Series/2023/05/24/\"\n",
			"metadata": {
				"trusted": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Carrega os DataFrames\ndf_movies_IMDB = spark.read.option(\"delimiter\", \"|\").csv(path1 + 'movies.csv', header=True)\ndf_series_IMDB = spark.read.option(\"delimiter\", \"|\").csv(path2 + 'series.csv', header=True)\ndf_movies_TMDB = spark.read.json(path3 + 'movies_20230524_160604.json') \ndf_series_TMDB = spark.read.json(path4 + 'series_20230524_160604.json')",
			"metadata": {
				"trusted": true
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## 2. \n Filtro os Filmes do BD Local com lista de filmes do TMDB",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Converter a coluna 'title' do DataFrame JSON para um array de palavras e extrair o ano de lançamento\ndf_filmes_titulos_datas = df_movies_TMDB.select(col('title'), substring(col('release_date'), 1, 4).alias('releaseDate'))\n\n# Definir o tamanho mínimo das palavras em comum\ntamanho_minimo = 4\n\n# Realizar a filtragem dos títulos\ndf_movies_IMDB_trusted = df_movies_IMDB.join(df_filmes_titulos_datas,\n                                   (df_movies_IMDB['tituloPincipal'].contains(df_filmes_titulos_datas['title'])) &\n                                   (df_movies_IMDB['anoLancamento'] == df_filmes_titulos_datas['releaseDate']),\n                                   'inner')\n\n# Remover as colunas 'title' e 'releaseDate' do DataFrame\ndf_movies_IMDB_trusted = df_movies_IMDB_trusted.drop('title', 'releaseDate')\n\n# Renomear a coluna 'tituloPincipal' para 'tituloPrincipal' no DataFrame df_IMDB_filtrado_filmes\ndf_movies_IMDB_trusted = df_movies_IMDB_trusted.withColumnRenamed(\"tituloPincipal\", \"tituloPrincipal\")\n\ndf_movies_IMDB_trusted = df_movies_IMDB_trusted.distinct()\n\n# Trata os valores \"NA\" na coluna \"anoFalecimento\"\ndf_movies_IMDB_trusted = df_movies_IMDB_trusted.withColumn(\"anoFalecimento\", when(col(\"anoFalecimento\") == \"\\\\N\", None).otherwise(col(\"anoFalecimento\")))\n\n",
			"metadata": {
				"trusted": true
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## 3. \nFiltro as Series do BD Local com lista de series do TMDB",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Converter a coluna 'name' e a substring de 'first_air_date' do DataFrame JSON para o DataFrame do TMDB\ndf_series_nomes_datas = df_series_TMDB.select(col('name'), substring(col('first_air_date'), 1, 4).alias('dataLancamento'))\n\n# Realizar a filtragem dos títulos e anos de lançamento\ndf_series_IMDB_layer1 = df_series_IMDB.join(df_series_nomes_datas,\n                                         (df_series_IMDB['tituloPincipal'].contains(df_series_nomes_datas['name'])) &\n                                         (df_series_IMDB['anoLancamento'] == df_series_nomes_datas['dataLancamento']),\n                                         'inner')\n\n# Remover as colunas 'name' e 'dataLancamento' do DataFrame\ndf_series_IMDB_layer1 = df_series_IMDB_layer1.drop('name', 'dataLancamento')\n\ndf_series_IMDB_layer1 = df_series_IMDB_layer1.distinct()\n\n# Renomear a coluna 'tituloPincipal' para 'tituloPrincipal' no DataFrame df_IMDB_filtrado_filmes\ndf_series_IMDB_layer1 = df_series_IMDB_layer1.withColumnRenamed(\"tituloPincipal\", \"tituloPrincipal\")\n\n\n",
			"metadata": {
				"trusted": true
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## 4. \nFiltro as Series do BD Local que foram filtradas no passo 3\n\ncom a dos filmes do BD local que foram filtrados no passo 2",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Filtrar apenas os títulos das séries correspondentes aos filmes\ndf_filmes_correspondentes = df_movies_IMDB_trusted.select(col('tituloPrincipal').alias('titulo'))\n\n# Realizar a junção entre os dataframes de séries e títulos correspondentes usando contains\ndf_series_IMDB_trusted = df_series_IMDB_layer1.join(df_filmes_correspondentes,\n                                            df_series_IMDB_layer1['tituloPrincipal'].contains(df_filmes_correspondentes['titulo']),\n                                            'inner')\n\ndf_series_IMDB_trusted = df_series_IMDB_trusted.drop('titulo')\n\n# Remover linhas duplicadas no resultado\ndf_series_IMDB_trusted = df_series_IMDB_trusted.distinct()\n\n# Trata os valores \"NA\" nas colunas\ndf_series_IMDB_trusted = df_series_IMDB_trusted.withColumn(\"anoNascimento\", when(col(\"anoNascimento\") == \"\\\\N\", None).otherwise(col(\"anoNascimento\")))\ndf_series_IMDB_trusted = df_series_IMDB_trusted.withColumn(\"anoFalecimento\", when(col(\"anoFalecimento\") == \"\\\\N\", None).otherwise(col(\"anoFalecimento\")))\ndf_series_IMDB_trusted = df_series_IMDB_trusted.withColumn(\"anoTermino\", when(col(\"anoTermino\") == \"\\\\N\", None).otherwise(col(\"anoTermino\")))\ndf_series_IMDB_trusted = df_series_IMDB_trusted.withColumn(\"tempoMinutos\", when(col(\"tempoMinutos\") == \"\\\\N\", None).otherwise(col(\"tempoMinutos\")))\n",
			"metadata": {
				"trusted": true
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## 5. \nFiltro as Series do TMDB com lista de Filmes do TMDB",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Filtrar apenas os títulos das séries correspondentes aos filmes\ndf_filmes_titulos = df_movies_TMDB.select(col('title').alias('titulo'))\n\n# Realizar a junção entre os dataframes de séries e títulos correspondentes usando contains\ndf_series_TMDB_trusted = df_series_TMDB.join(df_filmes_titulos,\n                                            df_series_TMDB['name'].contains(df_filmes_titulos['titulo']),\n                                            'inner')\n\ndf_series_TMDB_trusted = df_series_TMDB_trusted.drop('titulo','backdrop_path','poster_path')\n\n# Remover linhas duplicadas no resultado\ndf_series_TMDB_trusted = df_series_TMDB_trusted.distinct()\n\n# Trata os valores \"NA\" nas colunas\ndf_series_TMDB_trusted = df_series_TMDB_trusted.withColumn(\"first_air_date\", when(col(\"first_air_date\") == \"\", None).otherwise(col(\"first_air_date\")))\ndf_series_TMDB_trusted = df_series_TMDB_trusted.withColumn(\"genre_ids\", when(size(col(\"genre_ids\")) == 0, None).otherwise(col(\"genre_ids\")))\ndf_series_TMDB_trusted = df_series_TMDB_trusted.withColumn(\"overview\", when(col(\"overview\") == \"\", None).otherwise(col(\"overview\")))\n",
			"metadata": {
				"trusted": true
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## 6.\nElimina algumas colunas não relevantes do df_movies_TMDB ",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# remove os colunas não relevantes\ndf_movies_TMDB_trusted = df_movies_TMDB.drop('adult','backdrop_path','poster_path','video')",
			"metadata": {
				"trusted": true
			},
			"execution_count": 12,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## 7.\nescreve os dados na camada Trusted no S3 no formato parquet\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "# Obtém a data atual para criar os diretórios correspondentes\ncurrent_date = datetime.now()\nano = current_date.strftime(\"%Y\")\nmes = current_date.strftime(\"%m\")\ndia = current_date.strftime(\"%d\")\n\n# Define os caminhos de destino no S3 para os DataFrames no formato Parquet\npath_trt_local_movies = \"s3://data-lake-do-fabricio/TRT/Local/Filmes/{ano}/{mes}/{dia}/\"\npath_trt_local_series = \"s3://data-lake-do-fabricio/TRT/Local/Series/{ano}/{mes}/{dia}/\"\npath_trt_tmdb_movies = \"s3://data-lake-do-fabricio/TRT/TMDB/Filmes/{ano}/{mes}/{dia}/\"\npath_trt_tmdb_series = \"s3://data-lake-do-fabricio/TRT/TMDB/Series/{ano}/{mes}/{dia}/\"\n\n# Salva os DataFrames no formato Parquet no S3\ndf_movies_IMDB_trusted.write.parquet(path_trt_local_movies.format(ano=ano, mes=mes, dia=dia))\ndf_series_IMDB_trusted.write.parquet(path_trt_local_series.format(ano=ano, mes=mes, dia=dia))\ndf_movies_TMDB_trusted.write.parquet(path_trt_tmdb_movies.format(ano=ano, mes=mes, dia=dia))\ndf_series_TMDB_trusted.write.parquet(path_trt_tmdb_series.format(ano=ano, mes=mes, dia=dia))",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		}
	]
}
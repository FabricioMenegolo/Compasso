{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Requirement already satisfied: pyspark in /opt/apache-spark/python (3.3.0)\n",
						"Requirement already satisfied: py4j==0.10.9.5 in /home/fmenegolo/.asdf/installs/python/3.9.1/lib/python3.9/site-packages (from pyspark) (0.10.9.5)\n",
						"\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.1.2 is available.\n",
						"You should consider upgrading via the '/home/fmenegolo/.asdf/installs/python/3.9.1/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
						"Reshimming asdf python...\n"
					]
				}
			],
			"source": [
				"!pip install pyspark"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"/usr/sbin/hadoop\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"SLF4J: Class path contains multiple SLF4J bindings.\n",
						"SLF4J: Found binding in [jar:file:/opt/apache-spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
						"SLF4J: Found binding in [jar:file:/usr/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
						"SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
						"SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
						"Setting default log level to \"WARN\".\n",
						"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"23/06/05 16:36:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
					]
				}
			],
			"source": [
				"from pyspark.sql import SparkSession\n",
				"from pyspark import SparkContext, SQLContext\n",
				"from datetime import datetime\n",
				"from pyspark.sql.functions import col, substring, regexp_replace, expr, size, levenshtein, avg, when, format_number, sum, lower\n",
				"from pyspark.sql import functions as F\n",
				"\n",
				"spark = SparkSession \\\n",
				"    .builder \\\n",
				"    .master(\"local[*]\")\\\n",
				"    .appName(\"ELT Refined\") \\\n",
				"    .getOrCreate()\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"                                                                                \r"
					]
				}
			],
			"source": [
				"\n",
				"path1 = f\"/mnt/wsl/PHYSICALDRIVE2/Projects/Compasso/Azimute/Sprint_9/Desafio03_ETL/Tarefa_03/assets/Local/\"\n",
				"df_movies_IMDB_trusted = spark.read.parquet(path1 + 'movies_IMDB_trusted.parquet')\n",
				"df_series_IMDB_trusted = spark.read.parquet(path1 + 'series_IMDB_trusted.parquet') \n",
				"\n",
				"path2 = f\"/mnt/wsl/PHYSICALDRIVE2/Projects/Compasso/Azimute/Sprint_9/Desafio03_ETL/Tarefa_03/assets/TMDB/\"\n",
				"df_movies_TMDB_trusted = spark.read.parquet(path2 + 'movies_TMDB_trusted.parquet')\n",
				"df_series_TMDB_trusted = spark.read.parquet(path2 + 'series_TMDB_trusted.parquet')\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 2. Normalização\n",
				"#### 2.1. Cria tabela movies IMDB"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [],
			"source": [
				"df_movies_IMDB = df_movies_IMDB_trusted.select(\"id\", \"tituloPrincipal\", \"tituloOriginal\", \"anoLancamento\", \"tempoMinutos\", \"genero\", \"notaMedia\", \"numeroVotos\")\n",
				"df_movies_IMDB = df_movies_IMDB.dropDuplicates(['id'])  # Remover duplicatas pelo ID\n",
				"df_movies_IMDB = df_movies_IMDB.withColumnRenamed(\"id\", \"movie_id\")  # Renomear a coluna \"id\" para \"movie_id\""
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### 2.2. Cria tabela series IMDB"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [],
			"source": [
				"df_series_IMDB = df_series_IMDB_trusted.select(\"id\", \"tituloPrincipal\", \"tituloOriginal\", \"anoLancamento\", \"anoTermino\", \"tempoMinutos\", \"genero\", \"notaMedia\", \"numeroVotos\")\n",
				"df_series_IMDB = df_series_IMDB.dropDuplicates(['id'])  # Remover duplicatas pelo ID\n",
				"df_series_IMDB = df_series_IMDB.withColumnRenamed(\"id\", \"seriesId\")  # Renomear a coluna \"id\" para \"movie_id\""
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 3.Junção \n",
				"\n",
				"### 3.1 Unir DF dos FILMES"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Aplicar regexp_replace no dataframe df_movies_TMDB\n",
				"df_movies_TMDB_titulos_datas = df_movies_TMDB_trusted.select(\n",
				"    regexp_replace(col('title'), r\"[^a-zA-Z0-9\\s]\", \"\").alias('title_replaced'),\n",
				"    substring(col('release_date'), 1, 4).alias('releaseDate'),\n",
				"    col('id'),\n",
				"    col('genre_ids'),\n",
				"    col('original_language'),\n",
				"    col('popularity'),\n",
				"    col('vote_average'),\n",
				"    col('vote_count'),\n",
				"    col('title'),\n",
				"    col('release_date')\n",
				")\n",
				"\n",
				"# Aplicar regexp_replace no dataframe df_movies_IMDB\n",
				"df_movies_IMDB_titulos_datas = df_movies_IMDB.select(\n",
				"    regexp_replace(col('tituloPrincipal'), r\"[^a-zA-Z0-9\\s]\", \"\").alias('tituloPrincipal_replaced'),\n",
				"    substring(col('anoLancamento'), 1, 4).alias('anoLancamento'),\n",
				"    col('movie_id'),\n",
				"    col('tituloOriginal'),\n",
				"    col('tempoMinutos'),\n",
				"    col('genero'),\n",
				"    col('notaMedia'),\n",
				"    col('numeroVotos')\n",
				")\n",
				"\n",
				"# Remover a sentença \"Final Chapter Part\" do dataframe df_movies_IMDB\n",
				"df_movies_IMDB_titulos_datas = df_movies_IMDB_titulos_datas.withColumn('tituloPrincipal_replaced', regexp_replace(col('tituloPrincipal_replaced'), 'Final Chapter Part', '')\n",
				")\n",
				"\n",
				"# Realizar a comparação de similaridade entre os títulos dos dataframes e filtrar pelo ano de lançamento\n",
				"df_movies_refined = df_movies_TMDB_titulos_datas.join(\n",
				"    df_movies_IMDB_titulos_datas,\n",
				"    expr(\n",
				"        \"(size(split(title_replaced, ' ')) = 1 AND \" +\n",
				"        \"size(filter(split(title_replaced, ' '), x -> length(x) > 3 AND instr(tituloPrincipal_replaced, x) > 0)) >= 1) OR \" +\n",
				"        \"(size(split(title_replaced, ' ')) = 2 AND \" +\n",
				"        \"size(filter(split(title_replaced, ' '), x -> length(x) >= 1 AND instr(tituloPrincipal_replaced, x) > 0)) >= 2) OR \" +\n",
				"        \"(size(split(title_replaced, ' ')) = 3 AND \" +\n",
				"        \"size(filter(split(title_replaced, ' '), x -> length(x) > 4 AND instr(tituloPrincipal_replaced, x) > 0)) >= 2) OR \" +\n",
				"        \"(size(split(title_replaced, ' ')) = 4 AND \" +\n",
				"        \"size(filter(split(title_replaced, ' '), x -> length(x) > 3 AND instr(tituloPrincipal_replaced, x) > 0)) >= 3) OR \" +\n",
				"        \"(size(split(title_replaced, ' ')) >= 5 AND \" +\n",
				"        \"size(filter(split(title_replaced, ' '), x -> length(x) >= 3 AND instr(tituloPrincipal_replaced, x) > 0)) >= 3 AND \" +\n",
				"        \"levenshtein(tituloPrincipal_replaced, title_replaced) <= 9)\"\n",
				"    ) &\n",
				"    (df_movies_TMDB_titulos_datas['releaseDate'] == df_movies_IMDB_titulos_datas['anoLancamento']) &\n",
				"    (col('tituloPrincipal_replaced').isNotNull()) &\n",
				"    (col('tituloPrincipal_replaced') != '') &\n",
				"    (col('title_replaced').isNotNull()) &\n",
				"    (col('title_replaced') != ''),\n",
				"    'left_outer'\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Calcular a soma de vote_count e numeroVotos (se não forem nulos)\n",
				"df_movies_refined = df_movies_refined.withColumn('votos', when(\n",
				"    col('vote_count').isNotNull() & col('numeroVotos').isNotNull(),\n",
				"    col('vote_count') + col('numeroVotos')\n",
				").otherwise(\n",
				"    when(col('vote_count').isNotNull(), col('vote_count')).otherwise(col('numeroVotos'))\n",
				"))\n",
				"\n",
				"# Calcular a média de vote_average e notaMedia (se não forem nulos)\n",
				"df_movies_refined = df_movies_refined.withColumn('nota_media', when(\n",
				"    col('vote_average').isNotNull() & col('notaMedia').isNotNull(),\n",
				"    format_number((col('vote_average') + col('notaMedia')) / 2, 1)\n",
				").otherwise(\n",
				"    when(col('vote_average').isNotNull(), format_number(col('vote_average'), 1)).otherwise(format_number(col('notaMedia'), 1))\n",
				"))\n",
				"\n",
				"# Apagar as colunas indesejadas\n",
				"df_movies_refined = df_movies_refined.drop('releaseDate', 'tituloPrincipal_replaced', 'anoLancamento', 'title_replaced','vote_average','vote_count','notaMedia','numeroVotos','tituloOriginal','genero')\n",
				"\n",
				"# Selecione apenas as colunas desejadas\n",
				"df_movies_refined = df_movies_refined.select('id','movie_id','genre_ids', 'title', 'tempoMinutos', 'release_date', 'original_language', 'popularity', 'nota_media', 'votos')\n",
				"\n",
				"df_movies_refined = df_movies_refined.distinct()\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### 3.2. Filtrar Series TMDB por Filme do TMDB (antes de unir DF SERIES)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Aplicar regexp_replace no dataframe df_series_TMDB\n",
				"\n",
				"df_series_TMDB_titulos_datas = df_series_TMDB_trusted.select(\n",
				"    substring(col('first_air_date'), 1, 4).alias('releaseDate'),\n",
				"    col('name_replaced'),\n",
				"    col('id'),\n",
				"    col('genre_ids'),\n",
				"    col('original_language'),\n",
				"    col('popularity'),\n",
				"    col('vote_average'),\n",
				"    col('vote_count'),\n",
				"    col('name'),\n",
				"    col('first_air_date')\n",
				")\n",
				"\n",
				"# dataframe df_movies_TMDB\n",
				"df_movies_TMDB_titulos_datas = df_movies_TMDB_titulos_datas.select(col('title_replaced'))\n",
				"\n",
				"# Realizar a comparação de similaridade entre os títulos dos dataframes e filtrar pelo ano de lançamento\n",
				"df_series_TMDB_Layer1 = df_series_TMDB_titulos_datas.join(\n",
				"    df_movies_TMDB_titulos_datas,\n",
				"    expr(\n",
				"        \"(size(split(name_replaced, ' ')) = 1 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) > 3 AND instr(title_replaced, x) > 0)) >= 1) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) = 2 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) >= 1 AND instr(title_replaced, x) > 0)) >= 2) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) = 3 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) > 4 AND instr(title_replaced, x) > 0)) >= 2) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) = 4 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) > 3 AND instr(title_replaced, x) > 0)) >= 3) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) >= 5 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) >= 3 AND instr(title_replaced, x) > 0)) >= 3 AND \" +\n",
				"        \"levenshtein(title_replaced, name_replaced) <= 8)\"\n",
				"    ) &\n",
				"    (col('title_replaced').isNotNull()) &\n",
				"    (col('title_replaced') != '') &\n",
				"    (col('name_replaced').isNotNull()) &\n",
				"    (col('name_replaced') != ''),\n",
				"    'inner'\n",
				")\n",
				"\n",
				"# Apagar as colunas indesejadas\n",
				"df_series_TMDB_Layer1 = df_series_TMDB_Layer1.drop('title_replaced')"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### 3.1 Unir DF das SERIES"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Aplicar regexp_replace no dataframe df_movies_IMDB\n",
				"df_series_IMDB_titulos_datas = df_series_IMDB.select(\n",
				"    regexp_replace(col('tituloPrincipal'), r\"[^a-zA-Z0-9\\s]\", \"\").alias('tituloPrincipal_replaced'),\n",
				"    substring(col('anoLancamento'), 1, 4).alias('anoLancamento'),\n",
				"    col('seriesId'),\n",
				"    col('tituloPrincipal'),\n",
				"    col('tempoMinutos'),\n",
				"    col('anoTermino'),\n",
				"    col('notaMedia'),\n",
				"    col('numeroVotos')\n",
				")\n",
				"\n",
				"# Realizar a comparação de similaridade entre os títulos dos dataframes e filtrar pelo ano de lançamento\n",
				"df_series_refined = df_series_TMDB_Layer1.join(\n",
				"    df_series_IMDB_titulos_datas,\n",
				"    expr(\n",
				"        \"(size(split(name_replaced, ' ')) = 1 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) > 3 AND instr(tituloPrincipal_replaced, x) > 0)) >= 1) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) = 2 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) >= 1 AND instr(tituloPrincipal_replaced, x) > 0)) >= 2) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) = 3 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) > 4 AND instr(tituloPrincipal_replaced, x) > 0)) >= 2) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) = 4 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) > 3 AND instr(tituloPrincipal_replaced, x) > 0)) >= 3) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) >= 5 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) >= 3 AND instr(tituloPrincipal_replaced, x) > 0)) >= 3 AND \" +\n",
				"        \"levenshtein(tituloPrincipal_replaced, name_replaced) <= 9)\"\n",
				"    ) &\n",
				"    (df_series_TMDB_Layer1['releaseDate'] == df_series_IMDB_titulos_datas['anoLancamento']) &\n",
				"    (col('tituloPrincipal_replaced').isNotNull()) &\n",
				"    (col('tituloPrincipal_replaced') != '') &\n",
				"    (col('name_replaced').isNotNull()) &\n",
				"    (col('name_replaced') != ''),\n",
				"    'left_outer'\n",
				")\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Calcular a soma de vote_count e numeroVotos (se não forem nulos)\n",
				"df_series_refined = df_series_refined.withColumn('votos', when(\n",
				"    col('vote_count').isNotNull() & col('numeroVotos').isNotNull(),\n",
				"    col('vote_count') + col('numeroVotos')\n",
				").otherwise(\n",
				"    when(col('vote_count').isNotNull(), col('vote_count')).otherwise(col('numeroVotos'))\n",
				"))\n",
				"\n",
				"# Calcular a média de vote_average e notaMedia (se não forem nulos)\n",
				"df_series_refined = df_series_refined.withColumn('nota_media', when(\n",
				"    col('vote_average').isNotNull() & col('notaMedia').isNotNull(),\n",
				"    format_number((col('vote_average') + col('notaMedia')) / 2, 1)\n",
				").otherwise(\n",
				"    when(col('vote_average').isNotNull(), format_number(col('vote_average'), 1)).otherwise(format_number(col('notaMedia'), 1))\n",
				"))\n",
				"\n",
				"# Apagar as colunas indesejadas\n",
				"df_series_refined = df_series_refined.drop('releaseDate', 'tituloPrincipal_replaced', 'releaseDate', 'name_replaced','vote_average','vote_count','notaMedia','numeroVotos','tituloPrincipal','anoLancamento')\n",
				"\n",
				"# Selecione apenas as colunas linhas desejadas\n",
				"df_series_refined = df_series_refined.select('id','seriesId','genre_ids', 'name', 'tempoMinutos', 'first_air_date', 'anoTermino', 'original_language', 'popularity', 'nota_media', 'votos')\n",
				"df_series_refined = df_series_refined.distinct()\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 4. Cria tabela actors  "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"metadata": {},
			"outputs": [],
			"source": [
				"\n",
				"# Cria DF Actors\n",
				"df_movies_actors = df_movies_IMDB_trusted.select(\"id\", \"personagem\", \"nomeArtista\", \"generoArtista\", \"anoNascimento\", \"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\")\n",
				"df_series_actors = df_series_IMDB_trusted.select(\"id\", \"personagem\", \"nomeArtista\", \"generoArtista\", \"anoNascimento\", \"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\")\n",
				"\n",
				"\n",
				"# Obter a lista de film_ids presentes na tabela de filmes selecionados\n",
				"filme_ids = df_movies_refined.select(\"movie_id\")\n",
				"serie_ids = df_series_refined.select(\"seriesId\")\n",
				"\n",
				"\n",
				"# Realizar o join entre os DataFrames\n",
				"df_movies_actors = df_movies_actors.join(filme_ids, df_movies_actors[\"id\"] == filme_ids[\"movie_id\"], \"inner\")\n",
				"df_series_actors = df_series_actors.join(serie_ids, df_series_actors[\"id\"] == serie_ids[\"seriesId\"], \"inner\")\n",
				"\n",
				"# Apaga coluna desnecessaria\n",
				"df_movies_actors = df_movies_actors.drop(\"movie_id\")\n",
				"df_series_actors = df_series_actors.drop(\"seriesId\")\n",
				"\n",
				"# Apaga dados repetidos\n",
				"df_movies_actors = df_movies_actors.distinct()\n",
				"df_series_actors = df_series_actors.distinct()\n",
				"\n",
				"# Unir df Atores de filmes e series\n",
				"df_actors = df_movies_actors.unionAll(df_series_actors)\n",
				"df_actors = df_series_actors.withColumn(\"IdArtista\", F.monotonically_increasing_id())  # Adicionar uma coluna de ID único para os artistas\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 5. Cria Views  "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 12,
			"metadata": {},
			"outputs": [],
			"source": [
				"df_movies_refined.createOrReplaceTempView(\"movies\")\n",
				"df_series_refined.createOrReplaceTempView(\"series\")\n",
				"df_actors.createOrReplaceTempView(\"actors\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"                                                                                \r"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+------+----------+-------------------+--------------------+------------+------------+-----------------+----------+----------+-----+\n",
						"|    id|  movie_id|          genre_ids|               title|tempoMinutos|release_date|original_language|popularity|nota_media|votos|\n",
						"+------+----------+-------------------+--------------------+------------+------------+-----------------+----------+----------+-----+\n",
						"|672322|tt11991748|[28, 12, 18, 10749]|Rurouni Kenshin: ...|         137|  2021-06-04|               ja|    42.752|       7.6| 9195|\n",
						"|349176|      null|  [28, 12, 35, 878]|Assassination Cla...|        null|  2015-03-21|               ja|    11.802|       7.3|  163|\n",
						"|221732| tt3029556|   [28, 12, 18, 14]|Rurouni Kenshin P...|         134|  2014-09-13|               ja|    21.811|       7.6|13723|\n",
						"+------+----------+-------------------+--------------------+------------+------------+-----------------+----------+----------+-----+\n",
						"only showing top 3 rows\n",
						"\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"                                                                                \r"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+-----+---------+------------------+--------------------+------------+--------------+----------+-----------------+----------+----------+------+\n",
						"|   id| seriesId|         genre_ids|                name|tempoMinutos|first_air_date|anoTermino|original_language|popularity|nota_media| votos|\n",
						"+-----+---------+------------------+--------------------+------------+--------------+----------+-----------------+----------+----------+------+\n",
						"|76409|tt7691766|        [18, 9648]|           Kakegurui|          24|    2018-01-16|      2019|               ja|    19.856|       7.3|  1242|\n",
						"|36041|tt1738419|      [16, 35, 18]|           Bakuman。|          24|    2010-10-02|      2013|               ja|    27.463|       8.1|  2572|\n",
						"|31911|tt1355642|[10759, 16, 10765]|Fullmetal Alchemi...|          24|    2009-04-05|      2010|               ja|    69.346|       8.9|169446|\n",
						"+-----+---------+------------------+--------------------+------------+--------------+----------+-----------------+----------+----------+------+\n",
						"only showing top 3 rows\n",
						"\n",
						"+---------+--------------------+-----------------+-------------+-------------+--------------+--------------------+---------------------+---------+\n",
						"|       id|          personagem|      nomeArtista|generoArtista|anoNascimento|anoFalecimento|           profissao|titulosMaisConhecidos|IdArtista|\n",
						"+---------+--------------------+-----------------+-------------+-------------+--------------+--------------------+---------------------+---------+\n",
						"|tt1738419|         KimNobuhiro|    Marc Diraison|        actor|         1975|          null|actor,miscellaneo...| tt0388629,tt22104...|        0|\n",
						"|tt2230515|  Lionet no SomaSoma|Katsuyuki Konishi|        actor|         1973|          null|actor,music_depar...| tt3208522,tt18694...|        1|\n",
						"|tt2230515|Sagittarius no Se...|      Tôru Furuya|        actor|         1953|          null|    actor,soundtrack| tt0851578,tt01033...|        2|\n",
						"+---------+--------------------+-----------------+-------------+-------------+--------------+--------------------+---------------------+---------+\n",
						"only showing top 3 rows\n",
						"\n"
					]
				}
			],
			"source": [
				"df_movies_refined.show(3)\n",
				"df_series_refined.show(3)\n",
				"df_actors.show(3)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"## 5. Escreve os dados na camada Refined no S3 no formato parquet\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 14,
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"'\\n# Obtém a data atual para criar os diretórios correspondentes\\ncurrent_date = datetime.now()\\nano = current_date.strftime(\"%Y\")\\nmes = current_date.strftime(\"%m\")\\ndia = current_date.strftime(\"%d\")\\n\\n# Define os caminhos de destino no S3 para os DataFrames no formato Parquet\\npath_ref_movies = \"s3://data-lake-do-fabricio/Refined/Filmes/{ano}/{mes}/{dia}/\"\\npath_ref_series = \"s3://data-lake-do-fabricio/Refined/Series/{ano}/{mes}/{dia}/\"\\npath_ref_actors = \"s3://data-lake-do-fabricio/Refined/Actors/{ano}/{mes}/{dia}/\"\\n\\n# Salva os DataFrames no formato Parquet no S3\\ndf_movies_refined.write.parquet(path_ref_movies.format(ano=ano, mes=mes, dia=dia))\\ndf_series_refined.write.parquet(path_ref_series.format(ano=ano, mes=mes, dia=dia))\\ndf_actors.write.parquet(path_ref_actors.format(ano=ano, mes=mes, dia=dia))\\n'"
						]
					},
					"execution_count": 14,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"\"\"\"\n",
				"# Obtém a data atual para criar os diretórios correspondentes\n",
				"current_date = datetime.now()\n",
				"ano = current_date.strftime(\"%Y\")\n",
				"mes = current_date.strftime(\"%m\")\n",
				"dia = current_date.strftime(\"%d\")\n",
				"\n",
				"# Define os caminhos de destino no S3 para os DataFrames no formato Parquet\n",
				"path_ref_movies = \"s3://data-lake-do-fabricio/Refined/Filmes/{ano}/{mes}/{dia}/\"\n",
				"path_ref_series = \"s3://data-lake-do-fabricio/Refined/Series/{ano}/{mes}/{dia}/\"\n",
				"path_ref_actors = \"s3://data-lake-do-fabricio/Refined/Actors/{ano}/{mes}/{dia}/\"\n",
				"\n",
				"# Salva os DataFrames no formato Parquet no S3\n",
				"df_movies_refined.write.parquet(path_ref_movies.format(ano=ano, mes=mes, dia=dia))\n",
				"df_series_refined.write.parquet(path_ref_series.format(ano=ano, mes=mes, dia=dia))\n",
				"df_actors.write.parquet(path_ref_actors.format(ano=ano, mes=mes, dia=dia))\n",
				"\"\"\"\n"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.9.1"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
